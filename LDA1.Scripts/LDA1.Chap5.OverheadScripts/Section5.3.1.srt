1
00:00:00,000 --> 00:00:03,200
Scripts:
Slide 0: Welcome back to the tutorial  

2
00:00:03,200 --> 00:00:10,720
on aggregate loss models. My name is Peng Shi, a 
professor in actuarial science at the University  

3
00:00:10,720 --> 00:00:18,160
of Wisconsin-Madison. In this video, I introduce 
the collective risk model that examines the  

4
00:00:18,160 --> 00:00:25,440
aggregate losses from an insurance entity using 
frequency and severity as building blocks.
 

5
00:00:25,440 --> 00:00:34,480
Slide 1: In the introduction, we have learned that 
conceptually a collective risk model examines the  

6
00:00:34,480 --> 00:00:41,120
losses at claim level, and calculates the 
total losses from all individual claims.
 

7
00:00:41,120 --> 00:00:49,280
Slide 2: Consider an insurance entity, be 
it a single policyholder or a portfolio of  

8
00:00:49,280 --> 00:00:57,840
policyholders. For a fixed period of time, let N
be the number of claims of the insurance entity,  

9
00:00:58,480 --> 00:01:07,920
and (X1,…,XN) be the corresponding amount of 
losses of individual claims. Then the aggregate  

10
00:01:07,920 --> 00:01:18,160
loss S is defined as the sum of X1,…,XN. We 
emphasize that in the collective risk model, N
 

11
00:01:18,160 --> 00:01:23,600
is a random number, which is in contrast 
to the individual risk model.
 

12
00:01:25,200 --> 00:01:29,040
There are several key assumptions 
in the collective risk model:  

13
00:01:29,600 --> 00:01:38,320
first, conditional on N=n
, X1,…,Xn are i.i.d. random variables;  

14
00:01:39,520 --> 00:01:46,720
second, the number of claims and the individual 
claim amount are independent with each other,  

15
00:01:47,600 --> 00:01:57,840
that is, the distribution of N does not depend 
on X1,…,XN, nor does the common distribution of  

16
00:01:57,840 --> 00:02:01,240
X1,…,XN on N
.
 

17
00:02:01,840 --> 00:02:08,000
In this model, we refer to N
as claim frequency, and X
 

18
00:02:08,000 --> 00:02:15,360
as claim severity. We note that frequency 
and severity are the two building blocks  

19
00:02:15,360 --> 00:02:22,720
in a collective risk model.
Slide 3: The aggregate loss S
 

20
00:02:22,720 --> 00:02:30,080
is said to follow a compound distribution. 
Its distribution function and density function  

21
00:02:30,080 --> 00:02:37,920
can be evaluated using the law of total 
probabilities. As we see, the computation  

22
00:02:37,920 --> 00:02:44,240
involves the n-fold convolution of X
, which makes it a challenging task.  

23
00:02:45,200 --> 00:02:50,800
We will discuss computing the distribution 
of aggregate loss in a separate video.
 

24
00:02:50,800 --> 00:03:00,000
Slide 4: Despite the challenge in computing 
distributional functions, the moments of S
 

25
00:03:00,000 --> 00:03:09,440
are ready to calculate. Using the law of iterated 
expectations, one could show that the mean of S  

26
00:03:10,080 --> 00:03:16,400
is equal to the product of expected 
frequency and expected severity of claims.  

27
00:03:17,760 --> 00:03:24,560
In addition, the variance of S is 
obtained using the law of total variation.  

28
00:03:25,600 --> 00:03:31,840
Both results rely on the independence 
assumption between N and X
 

29
00:03:31,840 --> 00:03:34,640
.
Slide 5:  

30
00:03:34,640 --> 00:03:43,200
Now let’s examine the model building process. The 
assumptions suggest that a collective risk model  

31
00:03:43,200 --> 00:03:51,040
can be built in three steps: First, one 
develops a frequency model for outcome N
 

32
00:03:51,040 --> 00:04:00,560
; Second, one develops a severity model 
for outcome X; The last step combines the  

33
00:04:00,560 --> 00:04:05,600
frequency and severity components 
to obtain the distribution of S
 

34
00:04:05,600 --> 00:04:09,120
.
Slide 6:  

35
00:04:09,120 --> 00:04:17,280
As you recall, Chapter two and Chapter three 
discussed fitting frequency and severity models  

36
00:04:17,280 --> 00:04:27,840
respectively. We use the Wisconsin property 
fund data as an example to reinforce the ideas.  

37
00:04:28,560 --> 00:04:39,040
We take a subsample of observations in year 2010. 
In this example, we use a collective risk model  

38
00:04:39,040 --> 00:04:47,280
to describe the total losses for an individual 
policyholder in a year. The data provides us a  

39
00:04:47,280 --> 00:04:58,560
random sample of 1,110 policyholders.
Slide 7: The frequency component is the  

40
00:04:58,560 --> 00:05:07,120
number of claims for a policyholder. Variable 
N is created to summarize the random sample  

41
00:05:07,120 --> 00:05:15,200
of claim frequency. The contingency table shows 
the number of policyholders for each value  

42
00:05:15,200 --> 00:05:20,960
of claim count. If we specify 
a parametric distribution,  

43
00:05:21,520 --> 00:05:29,040
such as Poisson or negative binomial, for N
, we could use the techniques introduced in  

44
00:05:29,040 --> 00:05:35,040
Chapter 2 to fit the frequency model.
Slide 8:  

45
00:05:35,040 --> 00:05:41,200
For the severity component, instead 
of using individual claim amount,  

46
00:05:42,000 --> 00:05:47,360
we examine the average amount of 
claims for individual policyholders.  

47
00:05:48,560 --> 00:05:56,000
Variable Xbar is created to summarize the 
random sample of average claim severity.  

48
00:05:57,360 --> 00:06:06,160
Note that Xbar is only defined for policyholders 
with at least one claims, i.e. N>0
 

49
00:06:06,160 --> 00:06:13,600
. The table shows the descriptive 
statistics of average claim amount.  

50
00:06:15,200 --> 00:06:22,240
If we specify a parametric distribution 
for Xbar, for instance, gamma or Pareto,  

51
00:06:23,280 --> 00:06:29,520
we could use the techniques introduced in 
Chapter 3 to fit the severity model.
 

52
00:06:29,520 --> 00:06:40,000
Slide 9: To summarize, in this section, we have 
learned how to build a collective risk model  

53
00:06:40,000 --> 00:06:48,240
for a portfolio of insurance contracts, calculate 
mean and variance of the aggregate loss,  

54
00:06:48,240 --> 00:06:57,360
and fit frequency and severity components in 
a collective risk model. Thanks for watching.

