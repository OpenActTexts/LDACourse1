1
00:00:00,560 --> 00:00:01,680
Hello everyone!

2
00:00:01,680 --> 00:00:08,080
My name is Michelle Xia, and I am an associate
professor at Northern Illinois University.

3
00:00:08,080 --> 00:00:10,560
In this lecture, I am going to introduce

4
00:00:10,560 --> 00:00:15,920
the basic frequency distributions
for modeling claim counts.

5
00:00:15,920 --> 00:00:22,160
For frequency distributions, the term frequency
refers to how often an insured event occurs,

6
00:00:22,160 --> 00:00:27,280
typically within a policy contract, for example,
one year for short-term insurance.

7
00:00:27,920 --> 00:00:31,200
Frequency modeling is often 
conducted in the contexts of

8
00:00:31,760 --> 00:00:35,600
ratemaking, stochastic 
reserving and claims analytics.

9
00:00:36,400 --> 00:00:41,680
In practice, discrete probability distributions,
called count distributions, are used to

10
00:00:41,680 --> 00:00:47,200
model the number of losses to a policyholder
or the number of claims to an insurance company.

11
00:00:49,120 --> 00:00:54,560
For basic frequency distributions, we first
introduce the probability foundations.

12
00:00:54,560 --> 00:00:59,840
In order to define count distributions, we
focus on the frequency random variable N

13
00:00:59,840 --> 00:01:04,400
with support on k = 0, 1, 2, up to infinity.

14
00:01:04,400 --> 00:01:07,840
That is, the random variable 
on the number of losses

15
00:01:07,840 --> 00:01:11,040
in the insurance context,
can take any whole number.

16
00:01:11,760 --> 00:01:18,000
Given the support, the frequency distribution
is characterized by the probability mass function,

17
00:01:18,000 --> 00:01:23,600
pmf, the probability that the random variable
takes each value k from its support.

18
00:01:23,600 --> 00:01:26,960
We use lower-case pk to denote the pmf. 

19
00:01:27,840 --> 00:01:31,600
Alternatively, we can use the 
cumulative distribution function,

20
00:01:31,600 --> 00:01:35,200
cdf, to uniquely determine 
the probability distribution 

21
00:01:35,200 --> 00:01:36,560
of a count random variable.

22
00:01:37,120 --> 00:01:43,840
The cdf is defined as the probability that
N takes a value no larger than x on the real line.

23
00:01:43,840 --> 00:01:50,560
The cdf F(x) can be calculated
as the sum of the pmfs associated with

24
00:01:50,560 --> 00:01:52,720
all whole numbers no larger than x.

25
00:01:53,760 --> 00:01:57,600
Furthermore, we can summarize distributions
through moments.

26
00:01:57,600 --> 00:02:02,960
The most commonly seen moment, the mean,
measures the center of the count distribution.

27
00:02:02,960 --> 00:02:08,160
The mean E(N), also denoted mu,
is the expectation of the random variable N,

28
00:02:08,160 --> 00:02:12,480
and can be calculated as
the sum of all possible values of k

29
00:02:12,480 --> 00:02:15,360
multiplied by its associated probability pk.

30
00:02:16,320 --> 00:02:18,880
Another commonly seen moment, variance,

31
00:02:18,880 --> 00:02:22,160
measures the variability of the random variable N.

32
00:02:22,160 --> 00:02:25,760
In particular, the variance Var(N) is defined

33
00:02:25,760 --> 00:02:30,720
as the expectation of the squared difference
between N and its mean mu, and can be

34
00:02:30,720 --> 00:02:35,760
calculated as the difference between the
expectation of N-squared and mu-squared.

35
00:02:38,080 --> 00:02:42,640
Other than the probability distribution functions
introduced in the previous slide,

36
00:02:42,640 --> 00:02:45,520
the distribution of a random 
variable can be determined 

37
00:02:45,520 --> 00:02:47,840
using probability generating functions.

38
00:02:48,480 --> 00:02:51,440
The probability generating function, pgf, 

39
00:02:51,440 --> 00:02:54,800
can uniquely determine the 
distribution of a random variable.

40
00:02:54,800 --> 00:03:01,920
The pgf, denoted capital P of some z,
is defined as the expectation of z of power N,

41
00:03:01,920 --> 00:03:08,160
and can be calculated as a weighted average of
z of power k with the weights being the pmfs.

42
00:03:08,880 --> 00:03:15,360
The name probability generating function comes
from the property that, taking the mth derivative

43
00:03:15,360 --> 00:03:21,840
and evaluating the function at 0, pgf generates
probabilities multiplied by m factorial.

44
00:03:22,400 --> 00:03:25,360
Further, pgf can generate moments.

45
00:03:25,360 --> 00:03:31,600
For example, taking the first derivative and
evaluating the function at 1 gives the mean E(N),

46
00:03:31,600 --> 00:03:35,760
and taking the second derivative
and evaluating the function at 1 gives

47
00:03:35,760 --> 00:03:41,040
the expectation of N times N-1,
which allows us to obtain the variance.

48
00:03:43,280 --> 00:03:46,400
After introducing the probability foundations, 

49
00:03:46,400 --> 00:03:49,920
we can now define important 
frequency distributions

50
00:03:49,920 --> 00:03:52,000
commonly seen in the actuarial context.

51
00:03:52,640 --> 00:03:56,960
In particular, there are three important frequency
distributions, including

52
00:03:56,960 --> 00:04:00,560
the Poisson, binomial and negative 
binomial distributions that

53
00:04:00,560 --> 00:04:02,320
we will introduce in this lecture.

54
00:04:02,880 --> 00:04:04,800
The three distributions are important

55
00:04:04,800 --> 00:04:09,200
because they fit well many 
insurance data sets of interest,

56
00:04:09,200 --> 00:04:13,200
and they provide the basis for more
complex distributions that even

57
00:04:13,200 --> 00:04:15,840
better approximate real situations of interest.

58
00:04:16,640 --> 00:04:20,880
In what follows, we will define these
three frequency distributions 

59
00:04:20,880 --> 00:04:23,920
based on the probability theories 
introduced earlier.

60
00:04:26,880 --> 00:04:31,200
The first important distribution we introduce
is the Poisson distribution

61
00:04:31,200 --> 00:04:34,160
that is commonly used to 
model count random variables 

62
00:04:34,160 --> 00:04:35,360
on the number of claims.

63
00:04:36,000 --> 00:04:39,120
The Poisson distribution
is a parametric distribution 

64
00:04:39,120 --> 00:04:44,800
that has a positive parameter lambda,
with its pmf pk given as follows. 

65
00:04:44,800 --> 00:04:48,640
The Poisson distribution
does not have a closed-form for its cdf

66
00:04:48,640 --> 00:04:53,840
but it can be numerically evaluated
given specific values of lambda.

67
00:04:53,840 --> 00:05:00,400
And its pgf capital P of z has the form
exponential lambda times z-1.

68
00:05:02,240 --> 00:05:06,400
The expectation of the Poisson 
distribution is lambda,

69
00:05:06,400 --> 00:05:09,840
which is the same as the variance.

70
00:05:10,480 --> 00:05:15,280
The second important frequency distribution,
the binomial distribution, is commonly used

71
00:05:15,280 --> 00:05:19,520
to model the number of successes
from a fixed number of binary trials.

72
00:05:20,400 --> 00:05:23,520
Thus, the binomial distribution 
has two parameters: 

73
00:05:23,520 --> 00:05:27,120
m on the number of trials
that is known from the design,

74
00:05:27,120 --> 00:05:31,680
and a parameter q on the probability
of success, between 0 and 1.

75
00:05:31,680 --> 00:05:35,280
The binomial pmf and pgf have the following forms.

76
00:05:36,320 --> 00:05:39,040
Based on the design of a binomial trial,

77
00:05:39,040 --> 00:05:43,840
the support of a binomial distribution contains
the values 0, 1, up to m.

78
00:05:44,640 --> 00:05:49,920
The binomial mean is m times q,
and the variance is m times q times 1-q.

79
00:05:51,120 --> 00:05:56,960
If the number of trials, m, equals 1, the
distribution is called a Bernoulli distribution.

80
00:05:58,320 --> 00:06:04,320
Here, as the probability q is between 0 and 1,
the variance is always smaller than the mean

81
00:06:04,320 --> 00:06:05,840
for binomial distributions.

82
00:06:08,240 --> 00:06:12,400
The third important frequency distribution
used for modeling claim counts

83
00:06:12,400 --> 00:06:14,320
is the negative binomial distribution.

84
00:06:14,880 --> 00:06:19,600
The negative binomial distribution has
two positive parameters, r and beta,

85
00:06:19,600 --> 00:06:24,000
and it models the number of successes
occurring before the rth failure.

86
00:06:24,640 --> 00:06:29,360
Here, beta divided by beta plus 1
denotes the probability of success,

87
00:06:29,360 --> 00:06:33,840
and the negative binomial pmf and pgf
have the following forms.

88
00:06:34,960 --> 00:06:39,600
The negative binomial distribution has
the expectation r times beta,

89
00:06:39,600 --> 00:06:42,960
and variance r times beta times 1 plus beta.

90
00:06:43,520 --> 00:06:48,800
If the parameter r equals 1, then
it is called a geometric distribution.

91
00:06:49,520 --> 00:06:53,040
Since beta is positive,
the negative binomial distribution

92
00:06:53,040 --> 00:06:56,320
has the property that
the variance is larger than the mean.

93
00:06:56,320 --> 00:07:00,880
It is useful for modeling
over-dispersed count data,

94
00:07:00,880 --> 00:07:04,480
where the empirical variance
is larger than the empirical mean.

95
00:07:05,920 --> 00:07:09,120
In this lecture, we have
learned the definitions and properties

96
00:07:09,120 --> 00:07:13,520
of basic frequency distributions
actuaries use to model the number of losses.

97
00:07:14,080 --> 00:07:19,040
We first determine quantities that summarize
a distribution such as the probability and

98
00:07:19,040 --> 00:07:23,360
distribution functions, as well as moments
such as the mean and variance.

99
00:07:23,920 --> 00:07:28,720
We then define and compute the moment and
probability generating functions.

100
00:07:29,440 --> 00:07:35,840
Last, we describe and understand relationships
among three important frequency distributions,

101
00:07:35,840 --> 00:07:40,320
the binomial, Poisson, and negative binomial
distributions that are commonly used

102
00:07:40,320 --> 00:07:43,520
for loss frequency data on the number of claims.

