Hi, I'm Brian Hartman from Brigham Young University. Today, we are going to be talking about tools for model selection. In order to discuss this, we're gonna use an example where we have some data and we think, well, this data might come from a gamma distribution, or it might come from pareto distribution. How can we tell which one it probably came from? 
One way to start is to look at just the CDFs and the PDFs and plot them on the same plot. And so we see here on the left, the CDFs of both the gamma and the pareto distribution in addition to the data, which are the dots. And you can see just by looking at it that the gamma distribution that's this line right here, doesn't seem to fit the data really well. Whereas the pareto distribution, this purple line right here, it seems to fit it really well. You could also look at the density functions or the PDFs. And again, we see that the gamma PDF is not that close to the kernel density estimate of the data, which is this black line. Whereas the purple line, which is the, the fitted Pareto is much closer. So it seems pretty likely that the pareto makes more sense. 
One other way you can do this is something called the P P plot. And this gives that empirical CDF at each observation on the horizontal axis. And so when you see that it seems to fit really well like it does in the plot on the right then most of these points are going to be near the X equals Y line. As we see with the gamma, we have this shape that obviously doesn't fit that X equals Y line. So again, this is more evidence that the Pareto was probably a better fit to this data than the gamma distribution. 
We'd also look at a QQ plot, which does quantiles instead of the probabilities. This also gives us a little more information. So we see again, looking at both the gamma quantile and the log gamma quantile, that both of those are pretty poor fits, but as we look at the Pareto quantile, we see that on this log scale it has a little bit of a hard time with these smaller observations. It does much better with the bigger observations. 
We might want to add a little more structure around this. While it's nice to look at pictures and say, this picture seems to fit better than the other. We might want to have some kind of structure and an actual hypothesis test. These are called goodness of fit tests. The idea behind these tests is that we first assume that the distribution generated the data and then we go looking for evidence that it didn't. Our null hypothesis is the data did come from that population. And our alternative is that the data did not. And so if we get enough evidence against that null hypothesis we're gonna reject the hypothesis. And we say that this model, or this distribution, is not a good fit for this data. 
One such goodness of fit test is called the Kolmogorov-Smirnov test, the KS test. What it does is it measures the max distance between the empirical CDF and the CDF of the fitted distribution. We can go back to our plots here, and I can give you an example. So in this case, if we were to do a test for the gamma distribution, looking over here at the CDFs, we would find the maximum distance between the gamma CDF and the empirical CDF. And it would be probably right here. And so that's a pretty big difference. And maybe that would mean that we reject that null hypothesis because the difference was so big. Alternatively, if we look at the Pareto fitted distribution, we see that the maximum distance is probably right here, but it's really, really small. Maybe that's not enough evidence to reject the null hypothesis. Maybe that would say the Pareto is decent. That's why the KS test looked at the maximum of these differences. Here are some possible critical values that you can look at. You can estimate any of these probabilities or P values from any software package. 
Another one, if you have grouped data is the Chi square test and the idea behind the Chi square tests with group data, as we say, under the model, we would expect to have X observations in this group and Y observations in this group, we actually have this and this, how close are those expected observations to the actual observations? So that's what this is right here. Here is the number of observations in category J minus the expected observations in category J squared over the expected observations in category J. Then you sum those all up for all the categories. And you get a test statistic, which is actually Chi squared distributed with degrees of freedom equal to the number of groups minus one minus R, which is the number of groups or estimated parameters. So that's another way that you can test whether that distribution seems to fit well or not. 
So we learned how to summarize data graphically. We learned how to summarize through goodness of fit tests. And we look forward to the next section, which is likelihood ratio tests and goodness of fit tests.
